# DocuMind ğŸ§ ğŸ“„

**DocuMind** is an intelligent RAG (Retrieval-Augmented Generation) document chat application that allows you to upload PDF documents and have natural conversations with them using AI. Built with Next.js 15, it leverages Google Gemini for generation, Pinecone for vector storage, and LangChain for document processing.

![Next.js](https://img.shields.io/badge/Next.js-15-black)
![TypeScript](https://img.shields.io/badge/TypeScript-5.0-blue)
![License](https://img.shields.io/badge/license-MIT-green)

## âœ¨ Features

- ğŸ—¨ï¸ **Multi-Chat Interface** - Create and manage multiple chat sessions simultaneously
- ğŸ“¤ **PDF Upload & Indexing** - Upload PDF documents with automatic vectorization to Pinecone
- ğŸ¤– **AI-Powered Responses** - Get accurate answers grounded in your document content using Google Gemini 2.0
- ğŸ’¾ **Persistent Storage** - All chats, messages, and document metadata saved to MongoDB
- ğŸ¨ **Beautiful UI** - Modern, responsive interface with resizable panels and smooth animations
- ğŸ” **Smart Query Rewriting** - Automatic query enhancement for better retrieval results
- ğŸ“Š **Document Viewer** - Preview your uploaded PDFs directly in the app
- ğŸ¯ **Per-Chat Namespaces** - Isolated vector storage for each chat session
- ğŸ—‘ï¸ **Chat Management** - Delete chats with automatic cleanup of files and vectors
- âš¡ **Real-time Indexing Status** - Visual feedback during document processing

## ğŸ—ï¸ Tech Stack

### Frontend
- **Next.js 15** (App Router)
- **React 19**
- **TypeScript**
- **Tailwind CSS**

### Backend & AI
- **Google Gemini 2.0 Flash** - Query rewriting and response generation
- **Pinecone** - Vector database for embeddings
- **LangChain** - Document processing and chunking
- **MongoDB + Mongoose** - Chat and message persistence
- **pdf-parse** - PDF text extraction

## ğŸ“‹ Prerequisites

- Node.js 18+ and npm
- MongoDB instance (local or cloud)
- Google AI API key ([Get one here](https://ai.google.dev/))
- Pinecone account and API key ([Sign up here](https://www.pinecone.io/))

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone <your-repo-url>
cd documind
```

### 2. Install dependencies

```bash
npm install
```

### 3. Set up environment variables

Create a `.env.local` file in the root directory:

```env
# MongoDB
MONGODB_URI=mongodb://localhost:27017/documind

# Google AI (Gemini)
GEMINI_API_KEY=your_google_ai_api_key_here

# Pinecone
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX_NAME=documind

# Optional: Specify environment
PINECONE_ENVIRONMENT=your_pinecone_environment
```

### 4. Create the Pinecone index

Go to your Pinecone dashboard and create an index named `documind` with:
- **Dimensions**: 768 (for `text-embedding-004` model)
- **Metric**: Cosine similarity
- **Cloud**: AWS or GCP (your preference)

### 5. Run the development server

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to see the app.

## ğŸ“ Project Structure

```
documind/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ chats/              # Chat CRUD endpoints
â”‚   â”‚   â”œâ”€â”€ files/              # File serving endpoint
â”‚   â”‚   â””â”€â”€ upload/             # File upload handler
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â””â”€â”€ components/         # Chat UI components
â”‚   â”œâ”€â”€ globals.css             # Global styles
â”‚   â”œâ”€â”€ layout.tsx              # Root layout
â”‚   â””â”€â”€ page.tsx                # Landing page
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ models/                 # Mongoose schemas
â”‚   â”œâ”€â”€ indexers/               # Pinecone indexing utilities
â”‚   â””â”€â”€ mongoose.ts             # Database connection
â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ files/                  # Uploaded PDF storage
â””â”€â”€ public/                     # Static assets
```

## ğŸ¯ How It Works

1. **Create a Chat** - Start by creating a new chat session
2. **Upload a PDF** - Drag and drop a PDF document (auto-indexed to Pinecone)
3. **Ask Questions** - Type questions about your document
4. **Get AI Answers** - Receive contextual responses powered by Gemini

### Under the Hood

1. **Document Processing**:
   - PDF â†’ Text extraction (pdf-parse)
   - Text â†’ Chunks (RecursiveCharacterTextSplitter)
   - Chunks â†’ Embeddings (Google text-embedding-004)
   - Embeddings â†’ Pinecone (per-chat namespace)

2. **Query Flow**:
   - User question â†’ Query rewrite (Gemini improves clarity)
   - Rewritten query â†’ Embedding â†’ Pinecone similarity search
   - Retrieved context + original question â†’ Gemini â†’ Answer
   - Answer saved to MongoDB

## ğŸ”§ Configuration

### Adjusting Chunk Size

Edit `lib/indexers/pinecone.ts`:

```typescript
const splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 1000,        // Adjust chunk size
  chunkOverlap: 200,      // Adjust overlap
})
```

### Changing the LLM Model

Edit API routes to use a different Gemini model:

```typescript
const model = genAI.getGenerativeModel({ 
  model: 'gemini-2.0-flash-exp'  // or gemini-1.5-pro
})
```

## ğŸ› Troubleshooting

### MongoDB Connection Issues
- Ensure MongoDB is running: `mongod` or check your cloud connection string
- Verify `MONGODB_URI` in `.env.local`

### Pinecone Errors
- Check your index name matches `PINECONE_INDEX_NAME`
- Verify dimensions (768 for text-embedding-004)
- Ensure API key has proper permissions

### File Upload Fails
- Check `/uploads/files` directory exists and is writable
- Verify file size limits in `next.config.ts`

## ğŸ“ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/chats` | List all chats |
| POST | `/api/chats` | Create new chat |
| GET | `/api/chats/[chatId]` | Get chat with messages |
| DELETE | `/api/chats/[chatId]` | Delete chat + file + vectors |
| POST | `/api/chats/[chatId]/messages` | Send message, get AI response |
| POST | `/api/upload` | Upload PDF file |
| GET | `/api/files/[filename]` | Serve uploaded file |

## ğŸš€ Production Deployment

### Vercel (Recommended)

1. Push code to GitHub
2. Import project to Vercel
3. Add environment variables in Vercel dashboard
4. Deploy!

**Note**: For file uploads in production, consider using cloud storage (S3, Google Cloud Storage) instead of local filesystem.

### Docker

```bash
docker build -t documind .
docker run -p 3000:3000 --env-file .env.local documind
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- [Next.js](https://nextjs.org/) - The React framework
- [Google Gemini](https://ai.google.dev/) - Generative AI
- [Pinecone](https://www.pinecone.io/) - Vector database
- [LangChain](https://www.langchain.com/) - LLM orchestration
- [MongoDB](https://www.mongodb.com/) - Database

---

Built with â¤ï¸ using Next.js and AI
